{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trung bình bình phương sai số: 0.004641678440367148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cosyt\\pycharmprojects\\mlbasic\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# reading CSV file\n",
    "data = pd.read_csv(\"ex3Data/Admission_Predict.csv\")\n",
    "\n",
    "# Chọn 350 dòng đầu làm dữ liệu training, phần còn lại là dữ liệu test\n",
    "train_data = data.iloc[:350, :]\n",
    "test_data = data.iloc[350:, :]\n",
    "\n",
    "# Chuyển các dòng dữ liệu sang dạng cột (thêm .T vào sau)\n",
    "X_train = train_data.iloc[:, 1:8]\n",
    "Y_train = train_data.iloc[:, -1]\n",
    "Y_train1 = np.where(Y_train > 0.75, 1, 0)\n",
    "X_test = test_data.iloc[:, 1:8]\n",
    "Y_test = test_data.iloc[:, -1]\n",
    "Y_test1 = np.where(Y_test > 0.75, 1, 0)\n",
    "\n",
    "\n",
    "# Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol=1e-4, max_count=10000):\n",
    "    w = w_init\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_count:\n",
    "        # mix data for stochastic gradient descent method\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta * (yi - zi) * xi\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count % check_w_after == 0:\n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "    return w\n",
    "\n",
    "\n",
    "linear_regression = linear_model.LinearRegression()\n",
    "logregr = linear_model.LogisticRegression()\n",
    "\n",
    "logregr.fit(X_train, Y_train1)\n",
    "linear_regression.fit(X_train, Y_train)\n",
    "y_pred = linear_regression.predict(X_test)\n",
    "print(\"Trung bình bình phương sai số:\", mean_squared_error(Y_test, y_pred))\n",
    "# # Tìm hệ số w cho mô hình logistic regression\n",
    "# learning_rate = 0.01\n",
    "# num_iterations = 10000\n",
    "# d = X_train.shape[0]\n",
    "# w_init = np.random.randn(d, 1)\n",
    "# w = logistic_sigmoid_regression(X_train, Y_train, learning_rate, num_iterations)\n",
    "#\n",
    "# # Dự đoán kết quả cho tập test\n",
    "# print(w)\n",
    "# y_pred = sigmoid(np.dot(w.T, X_test))\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.74383210e-03 -1.72899079e-01  8.87861247e-03 -9.96735011e-03\n",
      "  -4.82777223e-01 -4.12036438e-03  4.01851763e-04 -2.23534143e-01\n",
      "   1.06095397e-02  1.27748974e+00 -1.01105269e+00  8.11322955e-01\n",
      "   2.94849368e-02 -1.21944097e+00 -1.49528995e-02  4.55751147e-01\n",
      "  -5.54244483e-02  7.55301524e-02  2.95799426e-03  4.58743044e-02\n",
      "  -7.05068489e-02 -1.01531499e-03  6.35962206e-03 -1.36080838e-02\n",
      "   1.20876268e-02 -6.68011746e-03 -2.76116478e-02  3.51246594e-02\n",
      "   5.20216075e-03  1.90895298e-02 -1.43130389e-02 -7.98060973e-03\n",
      "  -2.82765899e-02 -1.05844932e-02  9.23820402e-04  9.17986562e-03\n",
      "   6.80203745e-02  1.94116990e-01 -1.83507450e-01 -4.24740550e-01\n",
      "  -8.76686890e-01  1.31203698e+00]]\n",
      "Accuracy:  0.9780286477300315\n",
      "Recall:  0.6881188118811881\n",
      "Precision:  0.5408560311284046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cosyt\\pycharmprojects\\mlbasic\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# change to your data's path\n",
    "data = pd.read_csv(\"ex3Data/banking.csv\")\n",
    "data.head()\n",
    "# convert field of 'month'\n",
    "dict_month = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "              'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "data['month'] = data['month'].map(dict_month)\n",
    "# convert field of dayOfweek\n",
    "dict_day = {'sun': 1, 'mon': 2, 'tue': 3, 'wed': 4, 'thu': 5, 'fri': 6,\n",
    "            'sat': 7}\n",
    "data['day_of_week'] = data['day_of_week'].map(dict_day)\n",
    "# conver binary fields\n",
    "#default :\n",
    "data.default.replace({'no': 0, 'yes': 1, 'unknown': 2}, inplace=True)\n",
    "\n",
    "#housing :\n",
    "data.housing.replace({'no': 0, 'yes': 1, 'unknown': 2}, inplace=True)\n",
    "#loan :\n",
    "data.loan.replace({'no': 0, 'yes': 1, 'unknown': 2}, inplace=True)\n",
    "# convert categories field by one host coding\n",
    "marital_dummies = pd.get_dummies(data['marital'], prefix='marital')\n",
    "marital_dummies.drop('marital_divorced', axis=1, inplace=True)\n",
    "data = pd.concat([data, marital_dummies], axis=1)\n",
    "\n",
    "job_dummies = pd.get_dummies(data['job'], prefix='job')\n",
    "job_dummies.drop('job_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, job_dummies], axis=1)\n",
    "education_dummies = pd.get_dummies(data['education'], prefix='education')\n",
    "education_dummies.drop('education_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, education_dummies], axis=1)\n",
    "contact_dummies = pd.get_dummies(data['contact'], prefix='contact')\n",
    "#contact_dummies.drop('contact_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, contact_dummies], axis=1)\n",
    "poutcome_dummies = pd.get_dummies(data['poutcome'], prefix='poutcome')\n",
    "#poutcome_dummies.drop('poutcome_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, poutcome_dummies], axis=1)\n",
    "data['pdays'] = data['pdays'].apply(lambda row: 0 if row == -1 else 1)\n",
    "data.drop(['job', 'education', 'marital', 'contact', 'poutcome'], axis=1, inplace=True)\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:, 0:data.shape[0]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "loregr = linear_model.LogisticRegression(solver='lbfgs', penalty='l2')\n",
    "loregr.fit(X_train, Y_train)\n",
    "print(loregr.coef_)\n",
    "y_pred = loregr.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_pred, Y_test))\n",
    "print(\"Precision: \", precision_score(y_pred, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9963536918869644\n",
      "Precision Score: 1.0\n",
      "Recall Score: 0.9745222929936306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cosyt\\pycharmprojects\\mlbasic\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Bài 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "df = pd.read_csv(\"ex3Data/framingham.csv\")\n",
    "df.head()\n",
    "df.isnull().sum()\n",
    "df = df.dropna(how=\"any\", axis=0)\n",
    "X = df.iloc[:, 0:df.shape[0]]\n",
    "Y = df.iloc[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7)\n",
    "logregression = linear_model.LogisticRegression()\n",
    "logregression.fit(X_train, Y_train)\n",
    "Y_pred = logregression.predict(X_test)\n",
    "print('Accuracy Score:', accuracy_score(Y_test, Y_pred))\n",
    "print('Precision Score:', precision_score(Y_test, Y_pred))\n",
    "print('Recall Score:', recall_score(Y_test, Y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}